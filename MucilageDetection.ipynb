{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MucilageDetection.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"E3sewH60IJBF"},"source":["To work on colab, we need to add some paths and install libraries that are already installed on local computer. This part is not needed to run on local machine.\n","\n"]},{"cell_type":"code","metadata":{"id":"i9OPLHIBWCdd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644549760986,"user_tz":-180,"elapsed":17560,"user":{"displayName":"Bahri ABACI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmxMExAFfhFwsI2r_4D30AagUM0qq7gnyVeXQozA=s64","userId":"14058301516265489689"}},"outputId":"d68328e7-4fbb-45d4-8eb3-edd29e8474a0"},"source":["!pip install patchify\n","!pip install dropbox\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize\n","!pip install mat73"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting patchify\n","  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from patchify) (1.19.5)\n","Installing collected packages: patchify\n","Successfully installed patchify-0.2.3\n","Collecting dropbox\n","  Downloading dropbox-11.27.0-py3-none-any.whl (582 kB)\n","\u001b[K     |████████████████████████████████| 582 kB 8.6 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.16.2 in /usr/local/lib/python3.7/dist-packages (from dropbox) (2.23.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from dropbox) (1.15.0)\n","Collecting stone>=2.*\n","  Downloading stone-3.3.1-py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 59.8 MB/s \n","\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.16.2->dropbox) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.16.2->dropbox) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.16.2->dropbox) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.16.2->dropbox) (3.0.4)\n","Collecting ply>=3.4\n","  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n","\u001b[K     |████████████████████████████████| 49 kB 8.6 MB/s \n","\u001b[?25hInstalling collected packages: ply, stone, dropbox\n","Successfully installed dropbox-11.27.0 ply-3.11 stone-3.3.1\n","Collecting gputil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=cb3bf8424455d53b87e76e79abd843b0773993be1280f3a3bced9ff7988e5c02\n","  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n","Collecting mat73\n","  Downloading mat73-0.58-py3-none-any.whl (18 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mat73) (1.19.5)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from mat73) (3.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->mat73) (1.5.2)\n","Installing collected packages: mat73\n","Successfully installed mat73-0.58\n"]}]},{"cell_type":"markdown","metadata":{"id":"PXacKu0nWGr5"},"source":["We need to test the given GPU statistics"]},{"cell_type":"code","metadata":{"id":"LtWNhEn6WMKd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644549760986,"user_tz":-180,"elapsed":10,"user":{"displayName":"Bahri ABACI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmxMExAFfhFwsI2r_4D30AagUM0qq7gnyVeXQozA=s64","userId":"14058301516265489689"}},"outputId":"0d74e763-f0f1-4218-dca0-e4aac8f1f725"},"source":["# Import packages\n","import os,sys,humanize,psutil,GPUtil\n","\n","# Define function\n","def mem_report():\n","  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n","  \n","  GPUs = GPUtil.getGPUs()\n","  for i, gpu in enumerate(GPUs):\n","    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n","    \n","# Execute function\n","mem_report()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU RAM Free: 26.2 GB\n","GPU 0 ... Mem Free: 16280MB / 16280MB | Utilization   0%\n"]}]},{"cell_type":"markdown","metadata":{"id":"T-M57LdGI8gy"},"source":["## Define Optional Settings\n","\n","We need to set the necessary parameters for training. The path for the training and validation patches are automatically selected as local path or drive path.\n","\n","batchSize: set the mini batch size for the training\n","patchSize: number of patches that are cropped from the training images\n","loadAllAtOnce: load all data to memory before running, this will increase the training process but memory could be insufficient"]},{"cell_type":"code","metadata":{"id":"1wzCksKhJAc9"},"source":["# options\n","resolution = 20\n","patchSize = 300\n","patchOverlap = 116\n","batchSize = 16\n","patchCount = 200\n","numEpochs = 20\n","loadAllAtOnce = True\n","dataAugmentationTypes = ['original','hflip','vflip']\n","nband = 9\n","if resolution == 10:\n","  nband = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nBPu5RjTCsQw"},"source":["## Define Paths and Folders\n","\n","Define the paths and folders for the training and testing."]},{"cell_type":"code","metadata":{"id":"bNYK4jgNCZii"},"source":["import os\n","dropboxFolderPath = 'E:/Dropbox/'\n","\n","# define the paths relative to the dropbox folder\n","unetWorkingPath = os.path.join(dropboxFolderPath, 'Education/PhD/Projects/MucilageDetection/uNetLearning')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11Zhmbjbo_Rp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644549884538,"user_tz":-180,"elapsed":123558,"user":{"displayName":"Bahri ABACI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmxMExAFfhFwsI2r_4D30AagUM0qq7gnyVeXQozA=s64","userId":"14058301516265489689"}},"outputId":"ef910bcf-f318-4b6d-92f5-c09d79ce8d1a"},"source":["import sys\n","from google.colab import drive\n","\n","# mount the drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# override the local paths\n","unetWorkingPath = '/content/drive/Othercomputers/My Laptop/uNetLearning/'\n","\n","# add the paths to system paths \n","sys.path.append(unetWorkingPath)\n","sys.path.append(os.path.join(unetWorkingPath, 'functions'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"j090V7UhIYIu"},"source":["# Prepare For Train and Test\n","\n","Training code has been written in python. We use uNet architecture to segment the mucilage from the water. The implementation fulfilled with pyTorch. *italicized text*"]},{"cell_type":"code","metadata":{"id":"RSLXRmQIUC3J"},"source":["# define common paths\n","modelSavePath = os.path.join(unetWorkingPath, 'models')\n","sentinelPatchImagePath = os.path.join(unetWorkingPath, 'patches' + str(resolution))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6POCWujxItXo"},"source":["## Import Libraries\n","\n","To utilize training, we need to import necessary libraries. Some of the libraries are the standart pyTorch libarries and these can be imported via colab. The custom libraries are imported via the google drive."]},{"cell_type":"code","metadata":{"id":"s_X5MT2RIrZK"},"source":["# these are the standart libraries\n","import os\n","import torch\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader\n","from torchsummary import summary\n","\n","# mat file and set imports\n","import json\n","\n","# these are the custom libraries and will be imported from the drive\n","from unet.unet_model import UNet\n","from functions.ModelTrainer import train_model\n","from functions.SentinelLoader import SentinelPatchLoader\n","from functions.DataTransformer import GetDataTransformer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w-aVaKZGHMXO"},"source":["## Create Device"]},{"cell_type":"code","metadata":{"id":"ExZz6gLzHLCW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644549894124,"user_tz":-180,"elapsed":5,"user":{"displayName":"Bahri ABACI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmxMExAFfhFwsI2r_4D30AagUM0qq7gnyVeXQozA=s64","userId":"14058301516265489689"}},"outputId":"4a9517a6-44da-4438-a37e-956cdce2f980"},"source":["# create pytorch device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Training device is {device}')\n","\n","# clear GPU memory\n","if device == 'cuda':\n","  torch.cuda.empty_cache()\n","  torch.cuda.clear_cache()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training device is cuda\n"]}]},{"cell_type":"markdown","metadata":{"id":"aUqU9nQ7VIJm"},"source":["## Get DataTransformer for Training and Testing\n","\n","We use the same transformer (data normalizer) for train and test. But it depends on the spatial resolution of the input.\n"]},{"cell_type":"code","metadata":{"id":"qisYK83zVh-W"},"source":["transformer = GetDataTransformer(resolution)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TxePWbSyHBvt"},"source":["## Train and Validation Dataset"]},{"cell_type":"code","metadata":{"id":"7i8V6CFCJPaA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644550358579,"user_tz":-180,"elapsed":464458,"user":{"displayName":"Bahri ABACI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmxMExAFfhFwsI2r_4D30AagUM0qq7gnyVeXQozA=s64","userId":"14058301516265489689"}},"outputId":"f3fbd2f4-849b-47d2-d81f-a2a7f15b6c23"},"source":["# print the location of patches\n","if numEpochs > 0:\n","  print(f'Sentinel Patches will be used from {sentinelPatchImagePath}')\n","\n","  # define train images\n","  TrainingImages = [\"S2A_MSIL2A_20210509T084601_N0300_R107_T35TPF_20210509T115513\",\n","                    \"S2A_MSIL2A_20210512T085601_N0300_R007_T35TPF_20210512T133202\",\n","                    \"S2B_MSIL2A_20210514T084559_N0300_R107_T35TPF_20210514T113538\"]\n","  TrainingDataLoader = SentinelPatchLoader(sentinelPatchImagePath, TrainingImages, patchCount, dataAugmentationTypes, loadAllAtOnce, transformer)\n","\n","  # define validation images\n","  ValidationImages = [\"S2A_MSIL2A_20210519T084601_N0300_R107_T35TPF_20210519T115101\"]\n","  ValidationDataLoader = SentinelPatchLoader(sentinelPatchImagePath, ValidationImages, patchCount, dataAugmentationTypes, loadAllAtOnce, transformer)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentinel Patches will be used from /content/drive/Othercomputers/My Laptop/uNetLearning/patches20\n"]}]},{"cell_type":"code","metadata":{"id":"Q1HF5DxDXVcb"},"source":["# create custom data loader\n","if numEpochs > 0:\n","  TrainingDataLoader = {\n","      'train': DataLoader(TrainingDataLoader, batch_size=batchSize, shuffle=True, num_workers=0),\n","      'val': DataLoader(ValidationDataLoader, batch_size=batchSize, shuffle=True, num_workers=0)\n","  }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KUGOzvPoJVkb"},"source":["## Create Model\n","\n","Create the uNet model which has 9/10 channel input and 1 semantic class. After creating the model we will try to import the previous best weights for initialization. If the previous training run interrupted, code will try to recover from the last known state by loading the trainedModel. "]},{"cell_type":"code","metadata":{"id":"PWeVg0XlIGbg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644550369490,"user_tz":-180,"elapsed":10920,"user":{"displayName":"Bahri ABACI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmxMExAFfhFwsI2r_4D30AagUM0qq7gnyVeXQozA=s64","userId":"14058301516265489689"}},"outputId":"9ef90816-21d8-45de-ffce-09d1c71c6bd0"},"source":["# create a ResNetUNet model and apply it to model\n","if numEpochs > 0:\n","  trainModel = UNet(n_channels=nband, n_classes=1)\n","  trainModel = trainModel.to(device)\n","\n","  # print the model summary\n","  summary(trainModel, (nband, patchSize, patchSize))\n","\n","  # define optimizer and scheduler\n","  optimizer = optim.Adam(filter(lambda p: p.requires_grad, trainModel.parameters()), lr=0.0005)\n","  exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n","\n","  # check for previous model\n","  lastTrainedModelPath = os.path.join(modelSavePath, 'trainedModel' + str(resolution))\n","  preTrainedModelPath = os.path.join(modelSavePath,'bestModel' + str(resolution))\n","  if os.path.isfile(lastTrainedModelPath):\n","      print('loading the previous model...')\n","      \n","      # load the model\n","      checkpoint = torch.load(lastTrainedModelPath)\n","      trainModel.load_state_dict(checkpoint['model_state_dict'])\n","      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","      epoch = checkpoint['epoch']\n","      loss = checkpoint['loss']\n","  elif os.path.isfile(preTrainedModelPath):\n","      print('using the pre-trained model weights...')\n","      weights = torch.load(preTrainedModelPath)\n","      trainModel.load_state_dict(weights)\n","  else:\n","      print('no previous model found, training from scratch')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 300, 300]           5,248\n","       BatchNorm2d-2         [-1, 64, 300, 300]             128\n","              ReLU-3         [-1, 64, 300, 300]               0\n","            Conv2d-4         [-1, 64, 300, 300]          36,928\n","       BatchNorm2d-5         [-1, 64, 300, 300]             128\n","              ReLU-6         [-1, 64, 300, 300]               0\n","        DoubleConv-7         [-1, 64, 300, 300]               0\n","         MaxPool2d-8         [-1, 64, 150, 150]               0\n","            Conv2d-9        [-1, 128, 150, 150]          73,856\n","      BatchNorm2d-10        [-1, 128, 150, 150]             256\n","             ReLU-11        [-1, 128, 150, 150]               0\n","           Conv2d-12        [-1, 128, 150, 150]         147,584\n","      BatchNorm2d-13        [-1, 128, 150, 150]             256\n","             ReLU-14        [-1, 128, 150, 150]               0\n","       DoubleConv-15        [-1, 128, 150, 150]               0\n","             Down-16        [-1, 128, 150, 150]               0\n","        MaxPool2d-17          [-1, 128, 75, 75]               0\n","           Conv2d-18          [-1, 256, 75, 75]         295,168\n","      BatchNorm2d-19          [-1, 256, 75, 75]             512\n","             ReLU-20          [-1, 256, 75, 75]               0\n","           Conv2d-21          [-1, 256, 75, 75]         590,080\n","      BatchNorm2d-22          [-1, 256, 75, 75]             512\n","             ReLU-23          [-1, 256, 75, 75]               0\n","       DoubleConv-24          [-1, 256, 75, 75]               0\n","             Down-25          [-1, 256, 75, 75]               0\n","        MaxPool2d-26          [-1, 256, 37, 37]               0\n","           Conv2d-27          [-1, 512, 37, 37]       1,180,160\n","      BatchNorm2d-28          [-1, 512, 37, 37]           1,024\n","             ReLU-29          [-1, 512, 37, 37]               0\n","           Conv2d-30          [-1, 512, 37, 37]       2,359,808\n","      BatchNorm2d-31          [-1, 512, 37, 37]           1,024\n","             ReLU-32          [-1, 512, 37, 37]               0\n","       DoubleConv-33          [-1, 512, 37, 37]               0\n","             Down-34          [-1, 512, 37, 37]               0\n","        MaxPool2d-35          [-1, 512, 18, 18]               0\n","           Conv2d-36          [-1, 512, 18, 18]       2,359,808\n","      BatchNorm2d-37          [-1, 512, 18, 18]           1,024\n","             ReLU-38          [-1, 512, 18, 18]               0\n","           Conv2d-39          [-1, 512, 18, 18]       2,359,808\n","      BatchNorm2d-40          [-1, 512, 18, 18]           1,024\n","             ReLU-41          [-1, 512, 18, 18]               0\n","       DoubleConv-42          [-1, 512, 18, 18]               0\n","             Down-43          [-1, 512, 18, 18]               0\n","         Upsample-44          [-1, 512, 36, 36]               0\n","           Conv2d-45          [-1, 512, 37, 37]       4,719,104\n","      BatchNorm2d-46          [-1, 512, 37, 37]           1,024\n","             ReLU-47          [-1, 512, 37, 37]               0\n","           Conv2d-48          [-1, 256, 37, 37]       1,179,904\n","      BatchNorm2d-49          [-1, 256, 37, 37]             512\n","             ReLU-50          [-1, 256, 37, 37]               0\n","       DoubleConv-51          [-1, 256, 37, 37]               0\n","               Up-52          [-1, 256, 37, 37]               0\n","         Upsample-53          [-1, 256, 74, 74]               0\n","           Conv2d-54          [-1, 256, 75, 75]       1,179,904\n","      BatchNorm2d-55          [-1, 256, 75, 75]             512\n","             ReLU-56          [-1, 256, 75, 75]               0\n","           Conv2d-57          [-1, 128, 75, 75]         295,040\n","      BatchNorm2d-58          [-1, 128, 75, 75]             256\n","             ReLU-59          [-1, 128, 75, 75]               0\n","       DoubleConv-60          [-1, 128, 75, 75]               0\n","               Up-61          [-1, 128, 75, 75]               0\n","         Upsample-62        [-1, 128, 150, 150]               0\n","           Conv2d-63        [-1, 128, 150, 150]         295,040\n","      BatchNorm2d-64        [-1, 128, 150, 150]             256\n","             ReLU-65        [-1, 128, 150, 150]               0\n","           Conv2d-66         [-1, 64, 150, 150]          73,792\n","      BatchNorm2d-67         [-1, 64, 150, 150]             128\n","             ReLU-68         [-1, 64, 150, 150]               0\n","       DoubleConv-69         [-1, 64, 150, 150]               0\n","               Up-70         [-1, 64, 150, 150]               0\n","         Upsample-71         [-1, 64, 300, 300]               0\n","           Conv2d-72         [-1, 64, 300, 300]          73,792\n","      BatchNorm2d-73         [-1, 64, 300, 300]             128\n","             ReLU-74         [-1, 64, 300, 300]               0\n","           Conv2d-75         [-1, 64, 300, 300]          36,928\n","      BatchNorm2d-76         [-1, 64, 300, 300]             128\n","             ReLU-77         [-1, 64, 300, 300]               0\n","       DoubleConv-78         [-1, 64, 300, 300]               0\n","               Up-79         [-1, 64, 300, 300]               0\n","           Conv2d-80          [-1, 1, 300, 300]              65\n","          OutConv-81          [-1, 1, 300, 300]               0\n","================================================================\n","Total params: 17,270,849\n","Trainable params: 17,270,849\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 3.09\n","Forward/backward pass size (MB): 1289.91\n","Params size (MB): 65.88\n","Estimated Total Size (MB): 1358.89\n","----------------------------------------------------------------\n","loading the previous model...\n"]}]},{"cell_type":"markdown","metadata":{"id":"2WBeO7R4JXTG"},"source":["# Training Code\n","\n","Training code has been written in python. We use uNet architecture to segment the mucilage from the water. The implementation fulfilled with pyTorch."]},{"cell_type":"markdown","metadata":{"id":"kqfE4saUJMtc"},"source":["## Define Train and Test Set\n","\n","In this part we define **train** and **validation** set. Since we label only 4 images, we use 3 of them for training and 1 of them for validation. \n","\n","*Note that this part will take some time if the loadAllAtOnce flag set to True, but it will speed up the traing*"]},{"cell_type":"code","metadata":{"id":"4A4TKlhUJYjX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644552206539,"user_tz":-180,"elapsed":1837057,"user":{"displayName":"Bahri ABACI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmxMExAFfhFwsI2r_4D30AagUM0qq7gnyVeXQozA=s64","userId":"14058301516265489689"}},"outputId":"d9aac9a8-5788-4b12-c8e5-ac2e7f201034"},"source":["# start training\n","if numEpochs > 0:\n","  print('training model...')\n","  train_model(trainModel, optimizer, exp_lr_scheduler, TrainingDataLoader, device, num_epochs=numEpochs, outputPath=modelSavePath)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training model...\n","Epoch 0/19\n","----------\n","LR 0.000125\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"]},{"output_type":"stream","name":"stdout","text":["train: bce: 0.041184, dice: 0.194934, loss: 0.118059\n","val: bce: 0.056933, dice: 0.450134, loss: 0.253533\n","saving best model\n","1m 32s\n","Epoch 1/19\n","----------\n","LR 0.000125\n","train: bce: 0.035669, dice: 0.180452, loss: 0.108061\n","val: bce: 0.065600, dice: 0.492067, loss: 0.278833\n","1m 32s\n","Epoch 2/19\n","----------\n","LR 0.000125\n","train: bce: 0.035433, dice: 0.175526, loss: 0.105480\n","val: bce: 0.058326, dice: 0.461982, loss: 0.260154\n","1m 32s\n","Epoch 3/19\n","----------\n","LR 0.000125\n","train: bce: 0.034021, dice: 0.170441, loss: 0.102231\n","val: bce: 0.077164, dice: 0.518654, loss: 0.297909\n","1m 32s\n","Epoch 4/19\n","----------\n","LR 0.000125\n","train: bce: 0.033734, dice: 0.167239, loss: 0.100486\n","val: bce: 0.082265, dice: 0.528902, loss: 0.305583\n","1m 32s\n","Epoch 5/19\n","----------\n","LR 0.000125\n","train: bce: 0.033756, dice: 0.165062, loss: 0.099409\n","val: bce: 0.069368, dice: 0.449794, loss: 0.259581\n","1m 32s\n","Epoch 6/19\n","----------\n","LR 0.000125\n","train: bce: 0.032965, dice: 0.159879, loss: 0.096422\n","val: bce: 0.074240, dice: 0.487806, loss: 0.281023\n","1m 32s\n","Epoch 7/19\n","----------\n","LR 0.000125\n","train: bce: 0.033270, dice: 0.161308, loss: 0.097289\n","val: bce: 0.076887, dice: 0.514173, loss: 0.295530\n","1m 32s\n","Epoch 8/19\n","----------\n","LR 0.000125\n","train: bce: 0.033313, dice: 0.158845, loss: 0.096079\n","val: bce: 0.087100, dice: 0.515156, loss: 0.301128\n","1m 32s\n","Epoch 9/19\n","----------\n","LR 0.000125\n","train: bce: 0.032691, dice: 0.155388, loss: 0.094040\n","val: bce: 0.070589, dice: 0.477155, loss: 0.273872\n","1m 32s\n","Epoch 10/19\n","----------\n","LR 6.25e-05\n","train: bce: 0.031566, dice: 0.150716, loss: 0.091141\n","val: bce: 0.092628, dice: 0.512219, loss: 0.302423\n","1m 32s\n","Epoch 11/19\n","----------\n","LR 6.25e-05\n","train: bce: 0.031011, dice: 0.148491, loss: 0.089751\n","val: bce: 0.086732, dice: 0.482635, loss: 0.284684\n","1m 32s\n","Epoch 12/19\n","----------\n","LR 6.25e-05\n","train: bce: 0.031029, dice: 0.146801, loss: 0.088915\n","val: bce: 0.087714, dice: 0.529521, loss: 0.308618\n","1m 32s\n","Epoch 13/19\n","----------\n","LR 6.25e-05\n","train: bce: 0.031017, dice: 0.146587, loss: 0.088802\n","val: bce: 0.096049, dice: 0.504371, loss: 0.300210\n","1m 32s\n","Epoch 14/19\n","----------\n","LR 6.25e-05\n","train: bce: 0.030883, dice: 0.144699, loss: 0.087791\n","val: bce: 0.090230, dice: 0.509566, loss: 0.299898\n","1m 32s\n","Epoch 15/19\n","----------\n","LR 6.25e-05\n","train: bce: 0.030792, dice: 0.144571, loss: 0.087681\n","val: bce: 0.093805, dice: 0.498632, loss: 0.296218\n","1m 32s\n","Epoch 16/19\n","----------\n","LR 6.25e-05\n","train: bce: 0.030627, dice: 0.143241, loss: 0.086934\n","val: bce: 0.096914, dice: 0.510403, loss: 0.303659\n","1m 32s\n","Epoch 17/19\n","----------\n","LR 6.25e-05\n","train: bce: 0.030241, dice: 0.140771, loss: 0.085506\n","val: bce: 0.101329, dice: 0.516956, loss: 0.309142\n","1m 32s\n","Epoch 18/19\n","----------\n","LR 6.25e-05\n","train: bce: 0.030187, dice: 0.140306, loss: 0.085247\n","val: bce: 0.094809, dice: 0.496844, loss: 0.295827\n","1m 32s\n","Epoch 19/19\n","----------\n","LR 6.25e-05\n","train: bce: 0.030403, dice: 0.141112, loss: 0.085757\n","val: bce: 0.096080, dice: 0.514842, loss: 0.305461\n","1m 32s\n","Best val loss: 0.253533\n"]}]},{"cell_type":"markdown","metadata":{"id":"zg28-ixTAt6F"},"source":["# Test Model\n","\n","In this section we are going to use the model trained in the previous section and generate the output for different images."]},{"cell_type":"markdown","metadata":{"id":"1bfkqr9cZzQu"},"source":["## Create Model and Load the Best Weights\n","\n","Create the same model as in training phase and load the model parameters from the training."]},{"cell_type":"code","metadata":{"id":"VXMBxfo7e65U"},"source":["# include test related libraries\n","import numpy as np\n","import scipy.io as sio\n","import torch.nn.functional as func\n","\n","from functions.SentinelLoader import SentinelTestDataset\n","from functions.TestImagePathFinder import GetTestImagePath\n","from ImagePatchHandler import ImagePatchHandler"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"erXnicpeym7I"},"source":["## Create UNet model and load the weights"]},{"cell_type":"code","metadata":{"id":"TtAlQGVr_y-Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644552208864,"user_tz":-180,"elapsed":1538,"user":{"displayName":"Bahri ABACI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmxMExAFfhFwsI2r_4D30AagUM0qq7gnyVeXQozA=s64","userId":"14058301516265489689"}},"outputId":"d0bad9c8-32b7-4471-e59b-5444d7bf9234"},"source":["testModel = UNet(n_channels=nband, n_classes=1)\n","testModel = testModel.to(device)\n","print('loading pretrained model...')\n","testModel.load_state_dict(torch.load(os.path.join(modelSavePath, 'bestModel' + str(resolution))))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading pretrained model...\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["## Create Output Directory"],"metadata":{"id":"me71qplt7DS-"}},{"cell_type":"code","metadata":{"id":"N_3f1NLmZyJz"},"source":["# create output directory\n","outputDirectory = os.path.join(unetWorkingPath, \"outputs\")\n","if not os.path.exists(outputDirectory):\n","    os.makedirs(outputDirectory)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MSnCB-mfaTsR"},"source":["## Options\n","\n","Set the test options\n","\n","- modelResolution is needed for output array\n","- testbatchSize can be larger than the trainBatchSize\n","- cropZone is used to reduce tested patch size"]},{"cell_type":"code","source":["testBatchSize = 16"],"metadata":{"id":"OlKMcdSI7rNV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test Model on Images"],"metadata":{"id":"4AqMw87O7uXv"}},{"cell_type":"code","metadata":{"id":"aS6gW-nhaCZH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644553255451,"user_tz":-180,"elapsed":1046591,"user":{"displayName":"Bahri ABACI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmxMExAFfhFwsI2r_4D30AagUM0qq7gnyVeXQozA=s64","userId":"14058301516265489689"}},"outputId":"02f9c20e-e064-4cc5-8f92-2d5a8fa95a31"},"source":["scaler = resolution / 10\n","\n","# crop zone as x0,y0, width, height\n","cropZone = (0,0, int(8276 // scaler), int(3096 // scaler))\n","testImageFiles = 'testImages.json'\n","sentinelTestImagePath = '/Dataset/satellite/sentinel2/35TPE_MATDATA/'\n","\n","# crop zone as x0,y0, width, height\n","# cropZone = (0,0, int(10980 // scaler), int(10980 // scaler))\n","# testImageFiles = 'trainImages.json'\n","# sentinelTestImagePath = '/Dataset/satellite/sentinel2/35TPF_MATDATA/'\n","\n","jsonFile = open(os.path.join(unetWorkingPath, testImageFiles))\n","testImageFiles = json.load(jsonFile)\n","TestingImages = testImageFiles[str(resolution)]\n","jsonFile.close\n","\n","\n","# create patch handler\n","croppedImageSize = (cropZone[2], cropZone[3])\n","handler = ImagePatchHandler(croppedImageSize, (patchSize, patchSize), (patchOverlap, patchOverlap))\n","\n","# test the images one by one and save the result\n","for TestImage in TestingImages:\n","    \n","    # get the path to the image\n","    ImagePath = GetTestImagePath(dropboxFolderPath, sentinelTestImagePath, TestImage)\n","\n","    # create loader\n","    TestingDataLoader = SentinelTestDataset(ImagePath, cropZone, handler, transformer)\n","    \n","    # load the patches with batchSize\n","    TestDataLoader = {\n","        'test': DataLoader(TestingDataLoader, batch_size=testBatchSize, shuffle=False, num_workers=0)\n","    }\n","    \n","    # create output image\n","    result = np.zeros((croppedImageSize[1], croppedImageSize[0]), dtype=np.float32)\n","    \n","    # find the results\n","    for inputs, idx in TestDataLoader['test']:\n","        inputs = inputs.to(device)\n","    \n","        # get the result\n","        with torch.set_grad_enabled(False):\n","            outputs = func.sigmoid(testModel(inputs)).contiguous()\n","    \n","        # convert tensor to np array\n","        outputNP = outputs.cpu().detach().numpy()\n","        idxNP = idx.cpu().detach().numpy()\n","\n","        # add the result into the big array\n","        for i in range(outputNP.shape[0]):\n","          result = handler.SetPatchImage(result, outputNP[i,:,:,:], idxNP[i])\n","        \n","    # convert patches to image\n","    OutputFileName = os.path.splitext(TestImage)[0]+'_MUCILAGE.mat'\n","    sio.savemat(os.path.join(outputDirectory, OutputFileName), {'mucilage': result})"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading S2A_MSIL2A_20210102T090351_N0214_R007_T35TPE_20210102T115327_20m.mat...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"]},{"output_type":"stream","name":"stdout","text":["Downloading S2A_MSIL2A_20210119T085301_N0214_R107_T35TPE_20210119T115427_20m.mat...\n","Downloading S2A_MSIL2A_20210129T085221_N0214_R107_T35TPE_20210129T103011_20m.mat...\n","Downloading S2A_MSIL2A_20210221T090001_N0214_R007_T35TPE_20210221T115031_20m.mat...\n","Downloading S2A_MSIL2A_20210303T085851_N0214_R007_T35TPE_20210303T105606_20m.mat...\n","Downloading S2A_MSIL2A_20210313T085741_N0214_R007_T35TPE_20210313T112414_20m.mat...\n","Downloading S2A_MSIL2A_20210402T085551_N0300_R007_T35TPE_20210402T133128_20m.mat...\n","Downloading S2A_MSIL2A_20210422T085551_N0300_R007_T35TPE_20210422T122938_20m.mat...\n","Downloading S2A_MSIL2A_20210429T084601_N0300_R107_T35TPE_20210429T103912_20m.mat...\n","Downloading S2A_MSIL2A_20210509T084601_N0300_R107_T35TPE_20210509T115513_20m.mat...\n","Downloading S2A_MSIL2A_20210512T085601_N0300_R007_T35TPE_20210512T133202_20m.mat...\n","Downloading S2A_MSIL2A_20210519T084601_N0300_R107_T35TPE_20210519T115101_20m.mat...\n","Downloading S2A_MSIL2A_20210519T084601_N0300_R107_T35TPF_20210519T115101_20m.mat...\n","Downloading S2A_MSIL2A_20210611T085601_N0300_R007_T35TPE_20210611T121904_20m.mat...\n","Downloading S2A_MSIL2A_20210618T084601_N0300_R107_T35TPE_20210618T120513_20m.mat...\n","Downloading S2A_MSIL2A_20210628T084601_N0300_R107_T35TPE_20210628T103709_20m.mat...\n","Downloading S2A_MSIL2A_20210701T085601_N0301_R007_T35TPE_20210701T125029_20m.mat...\n","Downloading S2A_MSIL2A_20210711T085601_N0301_R007_T35TPE_20210711T121659_20m.mat...\n","Downloading S2A_MSIL2A_20210718T084601_N0301_R107_T35TPE_20210718T114908_20m.mat...\n","Downloading S2A_MSIL2A_20210728T084601_N0301_R107_T35TPE_20210728T111949_20m.mat...\n","Downloading S2A_MSIL2A_20210731T085601_N0301_R007_T35TPE_20210731T120834_20m.mat...\n","Downloading S2A_MSIL2A_20210807T084601_N0301_R107_T35TPE_20210807T114132_20m.mat...\n","Downloading S2A_MSIL2A_20210810T085601_N0301_R007_T35TPE_20210810T120517_20m.mat...\n","Downloading S2A_MSIL2A_20210817T084601_N0301_R107_T35TPE_20210817T114824_20m.mat...\n","Downloading S2A_MSIL2A_20210820T085601_N0301_R007_T35TPE_20210820T122214_20m.mat...\n","Downloading S2A_MSIL2A_20210827T084601_N0301_R107_T35TPE_20210827T102802_20m.mat...\n","Downloading S2A_MSIL2A_20210830T085601_N0301_R007_T35TPE_20210831T164139_20m.mat...\n","Downloading S2B_MSIL2A_20210203T085059_N0214_R107_T35TPE_20210203T111110_20m.mat...\n","Downloading S2B_MSIL2A_20210206T090039_N0214_R007_T35TPE_20210206T112619_20m.mat...\n","Downloading S2B_MSIL2A_20210223T084849_N0214_R107_T35TPE_20210223T111955_20m.mat...\n","Downloading S2B_MSIL2A_20210226T085829_N0214_R007_T35TPE_20210226T112525_20m.mat...\n","Downloading S2B_MSIL2A_20210305T084739_N0214_R107_T35TPE_20210305T111205_20m.mat...\n","Downloading S2B_MSIL2A_20210308T085719_N0214_R007_T35TPE_20210308T113808_20m.mat...\n","Downloading S2B_MSIL2A_20210328T085559_N0214_R007_T35TPE_20210328T113525_20m.mat...\n","Downloading S2B_MSIL2A_20210407T085549_N0300_R007_T35TPE_20210407T123314_20m.mat...\n","Downloading S2B_MSIL2A_20210414T084559_N0300_R107_T35TPE_20210414T112733_20m.mat...\n","Downloading S2B_MSIL2A_20210427T085549_N0300_R007_T35TPE_20210427T113845_20m.mat...\n","Downloading S2B_MSIL2A_20210507T085559_N0300_R007_T35TPE_20210507T192808_20m.mat...\n","Downloading S2B_MSIL2A_20210514T084559_N0300_R107_T35TPE_20210514T113538_20m.mat...\n","Downloading S2B_MSIL2A_20210517T085559_N0300_R007_T35TPE_20210517T112912_20m.mat...\n","Downloading S2B_MSIL2A_20210517T085559_N0300_R007_T35TPF_20210517T112912_20m.mat...\n","Downloading S2B_MSIL2A_20210524T084559_N0300_R107_T35TPE_20210524T111238_20m.mat...\n","Downloading S2B_MSIL2A_20210606T085559_N0300_R007_T35TPE_20210606T120423_20m.mat...\n","Downloading S2B_MSIL2A_20210613T084559_N0300_R107_T35TPE_20210613T113603_20m.mat...\n","Downloading S2B_MSIL2A_20210623T084559_N0300_R107_T35TPE_20210623T112759_20m.mat...\n","Downloading S2B_MSIL2A_20210626T085559_N0300_R007_T35TPE_20210626T114028_20m.mat...\n","Downloading S2B_MSIL2A_20210713T084559_N0301_R107_T35TPE_20210713T115731_20m.mat...\n","Downloading S2B_MSIL2A_20210716T085559_N0301_R007_T35TPE_20210716T112700_20m.mat...\n","Downloading S2B_MSIL2A_20210726T085559_N0301_R007_T35TPE_20210726T122123_20m.mat...\n","Downloading S2B_MSIL2A_20210802T084559_N0301_R107_T35TPE_20210802T110537_20m.mat...\n","Downloading S2B_MSIL2A_20210805T085559_N0301_R007_T35TPE_20210805T113028_20m.mat...\n","Downloading S2B_MSIL2A_20210812T084559_N0301_R107_T35TPE_20210812T105857_20m.mat...\n","Downloading S2B_MSIL2A_20210815T085559_N0301_R007_T35TPE_20210815T111606_20m.mat...\n","Downloading S2B_MSIL2A_20210822T084559_N0301_R107_T35TPE_20210822T110737_20m.mat...\n","Downloading S2B_MSIL2A_20210825T085559_N0301_R007_T35TPE_20210825T120947_20m.mat...\n"]}]},{"cell_type":"markdown","source":["## Test Model on Test Set"],"metadata":{"id":"FWaEB6Vp8As2"}},{"cell_type":"code","source":["# define train images\n","TestingImages = [\"S2A_MSIL2A_20210509T084601_N0300_R107_T35TPE_20210509T115513\",\n","                  \"S2B_MSIL2A_20210514T084559_N0300_R107_T35TPE_20210514T113538\",\n","                  \"S2B_MSIL2A_20210517T085559_N0300_R007_T35TPE_20210517T112912\",\n","                  \"S2A_MSIL2A_20210519T084601_N0300_R107_T35TPE_20210519T115101\"]\n","TestingDataLoader = SentinelPatchLoader(sentinelPatchImagePath, TestingImages, patchCount, dataAugmentationTypes, loadAllAtOnce, transformer)"],"metadata":{"id":"efQrMi0C8DN7","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"error","timestamp":1644677248697,"user_tz":-180,"elapsed":938,"user":{"displayName":"Bahri ABACI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhmxMExAFfhFwsI2r_4D30AagUM0qq7gnyVeXQozA=s64","userId":"14058301516265489689"}},"outputId":"a6087443-5cd7-40ca-818d-60a2b0a155de"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8cf1613f0666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0;34m\"S2B_MSIL2A_20210517T085559_N0300_R007_T35TPE_20210517T112912\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \"S2A_MSIL2A_20210519T084601_N0300_R107_T35TPE_20210519T115101\"]\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mTestingDataLoader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentinelPatchLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentinelPatchImagePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTestingImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatchCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataAugmentationTypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloadAllAtOnce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'SentinelPatchLoader' is not defined"]}]},{"cell_type":"code","source":["# load the patches with batchSize\n","TestDataLoader = {\n","    'test': DataLoader(TestingDataLoader, batch_size=1, shuffle=False, num_workers=0)\n","}\n","\n","# find the results\n","idx = 0\n","for inputs, labels in TestDataLoader['test']:\n","    inputs = inputs.to(device)\n","\n","    # get the result\n","    with torch.set_grad_enabled(False):\n","        outputs = func.sigmoid(testModel(inputs)).contiguous()\n","\n","    # get labels as contiguous array\n","    labelsC = labels.contiguous()\n","\n","    # convert tensor to np array\n","    outputNP = outputs.cpu().detach().numpy()\n","    labelsNP = labelsC.cpu().detach().numpy()\n","\n","    # save the results with the label\n","    OutputFileName = str(idx)+'_result.mat'\n","    sio.savemat(os.path.join(outputDirectory, OutputFileName), {'mucilage': outputNP, 'labels': labelsNP})\n","\n","    # go to the next index\n","    idx = idx + 1"],"metadata":{"id":"TbtLWQ4699ED"},"execution_count":null,"outputs":[]}]}